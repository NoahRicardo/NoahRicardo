<!DOCTYPE html>

<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>kafka 安装配置 [ NoahRicardo ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="../../../../css/iLiKE.css">
    
  
  
  
  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
    <script id="leancloud">
      AV.init({
          appId: "6E5zTbTljdUbVW2WkXPsXGJk-gzGzoHsz",
          appKey: "0vsyDKfNpeSECAI70J794ugv"
      });
    </script>

<meta name="generator" content="Hexo 5.4.2"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="../../../../favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">首页</a>
        
          
          
          
          
          
          
          <a href="/archives">归档</a>
        
          
          
          
          
          
          
          <a href="/about">关于</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">kafka 安装配置</h1>
<article class="post markdown-style">
  <h2 id="一、kafka-安装配置"><a href="#一、kafka-安装配置" class="headerlink" title="一、kafka 安装配置"></a>一、kafka 安装配置</h2><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，其在大数据开发应用上的目的是通过 Hadoo的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。大数据开发需掌握Kafka架构原理及各组件的作用和使用方法及相关功能的实现。</p>
<ul>
<li><p>上传文件包 到/export/server/</p>
</li>
<li><p>解压文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.11-2.0.0.tgz</span><br></pre></td></tr></table></figure></li>
<li><p>创建软连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s kafka_2.11-2.0.0/ kafka</span><br></pre></td></tr></table></figure></li>
<li><p>进入 /export/server/kafka/config  修改 配置文件 server.properties</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/kafka/config</span><br><span class="line"></span><br><span class="line">vim server.properties </span><br></pre></td></tr></table></figure>

<ul>
<li><p>21 行内容 broker.id=0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复（注：此处不用修改）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">21 broker.id=0</span><br></pre></td></tr></table></figure></li>
<li><p>31 行内容 #listeners=PLAINTEXT://:9092 取消注释，内容改为：listeners=PLAINTEXT://master:9092 </p>
<p>PLAINTEXT为通信使用明文（加密ssl）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">31 listeners=PLAINTEXT://master:9092 </span><br></pre></td></tr></table></figure></li>
<li><p>59 行内容  log.dirs=/tmp/kafka-logs 为默认日志文件存储的位置，改为 log.dirs=/export/server/data/kafka-logs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">59 log.dirs=/export/data/kafka-logs</span><br></pre></td></tr></table></figure></li>
<li><p>63 行内容为  num.partitions=1 是默认分区数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">63 num.partitions=1</span><br></pre></td></tr></table></figure></li>
<li><p>76 行部分</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">############################ **Log Flush Policy** ###############################</span><br><span class="line"> </span><br><span class="line">数据安全性（持久化之前先放到缓存上，从缓存刷到磁盘上）interval.messages   interval.ms</span><br></pre></td></tr></table></figure></li>
<li><p>93 行部分</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">########################### **Log Retention Policy** ############################</span><br><span class="line"> </span><br><span class="line">数据保留策略 168/24=7，1073741824/1024=1GB，300000ms = 300s = 5min超过了删掉（最后修改时间还是创建时间--&gt;日志段中最晚的一条消息，维护这个最大的时间戳--&gt;用户无法干预</span><br></pre></td></tr></table></figure></li>
<li><p>121 行内容 zookeeper.connect=localhost:2181 修改为 zookeeper.connect=master:2181,slave1:2181,slave2:2181</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">121 zookeeper.connect=master:2181,slave1:2181,slave2:2181</span><br></pre></td></tr></table></figure></li>
<li><p>126 行内容 group.initial.rebalance.delay.ms=0 修改为 group.initial.rebalance.delay.ms=3000</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">133 group.initial.rebalance.delay.ms=3000</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>给 slaves1和 slavs2 scp 分发 kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/</span><br><span class="line"></span><br><span class="line">scp -r /export/server/kafka_2.11-2.0.0/ slave1:$PWD</span><br><span class="line"></span><br><span class="line">scp -r /export/server/kafka_2.11-2.0.0/ slave2:$PWD</span><br></pre></td></tr></table></figure></li>
<li><p>创建软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /export/server/kafka_2.11-2.0.0/ kafka</span><br></pre></td></tr></table></figure></li>
<li><p>配置 kafka 环境变量（注：可以一台一台配，也可以在 master 完成后发给 slave1 和slave2）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka 环境变量</span></span><br><span class="line">export KAFKA_HOME=/export/server/kafka </span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin </span><br></pre></td></tr></table></figure></li>
<li><p>重新加载环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li>
<li><p>分别在 slave1 和slave2 上修改配置文件 路径：/export/server/kafka/config</p>
<ul>
<li><p>将文件 server.properties  的第 21 行的 broker.id=0 修改为 broker.id=1 同理 slave2 同样操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">21 broker.id=1</span><br></pre></td></tr></table></figure></li>
<li><p>将文件 server.properties  的第 31 行的 listeners=PLAINTEXT://master:9092 修改为 listeners=PLAINTEXT://slave1:9092 同理slave2 同样操作 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">31 listeners=PLAINTEXT://slave1:9092 </span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>启停 kafka (注：kafka 启动需要在 zookeeper 启动的情况下才可)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh -daemon /export/server/kafka/config/server.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">hadoop，zookeeper，kafka启动</span><br><span class="line">结果显示：</span><br><span class="line">(base) [root@master ~]# jps</span><br><span class="line">11793 NodeManager</span><br><span class="line">91699 Kafka</span><br><span class="line">85618 QuorumPeerMain</span><br><span class="line">10697 NameNode</span><br><span class="line">10924 DataNode</span><br><span class="line">11596 ResourceManager</span><br><span class="line">109852 Jps</span><br><span class="line"></span><br><span class="line">[root@slave1 ~]# jps</span><br><span class="line">9301 DataNode</span><br><span class="line">9493 SecondaryNameNode</span><br><span class="line">95959 Kafka</span><br><span class="line">102971 Jps</span><br><span class="line">9855 NodeManager</span><br><span class="line">89534 QuorumPeerMain</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# jps</span><br><span class="line">88660 QuorumPeerMain</span><br><span class="line">95204 Kafka</span><br><span class="line">9110 NodeManager</span><br><span class="line">8616 DataNode</span><br><span class="line">102104 Jps</span><br></pre></td></tr></table></figure></li>
<li><p>关闭 kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-stop.sh stop</span><br></pre></td></tr></table></figure></li>
<li><p>定制脚本一键启动</p>
</li>
<li><p>```sh<br>vim kafka-all.sh</p>
<p>放入 /bin 路径下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```shell</span><br><span class="line">#!/bin/bash</span><br><span class="line">if [ $# -eq 0 ] ;</span><br><span class="line">then</span><br><span class="line">	echo &quot;please input param:start stop&quot;</span><br><span class="line">else</span><br><span class="line">if [ $1 = start  ] ;then	</span><br><span class="line">	echo &quot;$&#123;1&#125;ing master&quot;</span><br><span class="line">	ssh master &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">	for i in &#123;1..2&#125;</span><br><span class="line">	do</span><br><span class="line">		echo &quot;$&#123;1&#125;ing slave$&#123;i&#125;&quot;	</span><br><span class="line">		ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">	done</span><br><span class="line">fi</span><br><span class="line">if [ $1 = stop ];then</span><br><span class="line">	echo &quot;$&#123;1&#125;ping master &quot;</span><br><span class="line">	ssh master &quot;source /etc/profile;kafka-server-stop.sh&quot;</span><br><span class="line">	for i in &#123;1..2&#125;</span><br><span class="line">	do</span><br><span class="line">		echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot;	</span><br><span class="line">		ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-stop.sh&quot;</span><br><span class="line">	done</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4>
</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="/2022/06/05/%E4%BA%8C%E3%80%81Kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/">上一篇</a>
    

    
    <p>上次更新 2022-06-05</p>
    
    
        <a class="extend next post-next" href="/2022/06/05/3%E3%80%81Spark%20HA%20&amp;%20Yarn%E9%85%8D%E7%BD%AE/">下一篇</a>
    
    </div>


    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:NoahRicardo@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/NoahRicardo/" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © NoahRicardo 2017 - 2022
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>
    </div>
</body>
</html>
